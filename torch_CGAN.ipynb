{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "torch_CGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOhNNdsfDP/aor67U83LmTa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fractal2k/Learning-Deep-Learning/blob/master/torch_CGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HD1SOUgU3CI5",
        "colab_type": "text"
      },
      "source": [
        "# Conditional GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9Tpo9Gbu-W1",
        "colab_type": "text"
      },
      "source": [
        "A vanillla GAN samples randomly from the normal distribution vector that we provide it. That aspect makes it unusable for practical applications.<br>The cGAN attempts to overcome that problem by conditioning the generator on labels of the output we want it to generate. Below is a very basic MNIST generator implementation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ez8-zZoH3HAy",
        "colab_type": "text"
      },
      "source": [
        "## Necessary Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quqMQTY6qjAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.optimizer import Optimizer\n",
        "\n",
        "import torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oyOSFOLq9W0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "# FIXED_SIZE = 16  # \n",
        "Z_LEN = 100  # Noise vector length\n",
        "BETA1 = 0.5  # Adam beta parameters\n",
        "BETA2 = 0.999  # Adam beta parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37CjjY9B3K-T",
        "colab_type": "text"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2M3BmUCrMP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = torchvision.transforms.Compose([\n",
        "                                            torchvision.transforms.ToTensor(),\n",
        "                                            torchvision.transforms.Normalize((0.5,), (0.5,))])\n",
        "trainset = torchvision.datasets.MNIST(root='', train=True, transform=transform, download=True)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRVgxVa9r5w6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TO3yfp_3rB9i",
        "colab_type": "text"
      },
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWncKLZvr_ac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Noise sampled from the standard normal distribution, input for the generator\n",
        "def generate_noise(batch_size):\n",
        "    return torch.randn(batch_size, Z_LEN, 1, 1, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_79ArGNsP6K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The DCGAN paper says that all the weights must be randomly initialized with \n",
        "# mean=0 and stddev=0.02\n",
        "# So, we create a custom function to initialize the weights of the network\n",
        "def weights_initialization(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3s7ZWu3rF0O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b26d238f-a821-4ae2-828d-549370984207"
      },
      "source": [
        "def display_img(imgs, num_imgs):\n",
        "    npimg = imgs.detach().numpy()\n",
        "    npimg = npimg / 2 + 0.5\n",
        "    fig = plt.figure(figsize=(4, 4))\n",
        "\n",
        "    if num_imgs == 1:\n",
        "        plt.imshow(npimg, cmap='gray')\n",
        "        plt.axis('off')\n",
        "    else:\n",
        "        for i in range(num_imgs):\n",
        "            plt.subplot(4, 4, i + 1)\n",
        "            plt.imshow(npimg[i, :, :], cmap='gray')\n",
        "            plt.axis('off')\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeX821Do3Pr6",
        "colab_type": "text"
      },
      "source": [
        "## Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVjMNB55s48z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConditionalGenerator(nn.Module):\n",
        "    r\"\"\"Generator of the CGAN setup\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, num_classes):\n",
        "        super(ConditionalGenerator, self).__init__()\n",
        "\n",
        "        # We use the embedding layer to convert the label into an embedding\n",
        "        # of size z_len\n",
        "        # TODO: Experiment with other manipulations for the label\n",
        "        self.input_dim = input_dim\n",
        "        self.embedding_layer = nn.Embedding(num_classes, input_dim)\n",
        "\n",
        "        self.deconvolutions = nn.Sequential(\n",
        "            nn.ConvTranspose2d(input_dim, 512, 3, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(True),\n",
        "            # Output: 3x3\n",
        "\n",
        "            nn.ConvTranspose2d(512, 256, 3, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(True),\n",
        "            # Output: 5x5\n",
        "\n",
        "            nn.ConvTranspose2d(256, 128, 3, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "            # Output: 7x7\n",
        "\n",
        "            nn.ConvTranspose2d(128, 64, 2, stride=2, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(True),\n",
        "            # Output: 14x14\n",
        "\n",
        "            nn.ConvTranspose2d(64, 1, 2, stride=2, bias=False),\n",
        "            nn.Tanh()\n",
        "            # Output: 28x28\n",
        "        )\n",
        "    \n",
        "    def forward(self, z, label):\n",
        "        # Convert label into embedding and reshape into proper format for deconvolving\n",
        "        embedding = torch.reshape(self.embedding_layer(label), (-1, self.input_dim, 1, 1))\n",
        "        # Multiply input vector with embedding\n",
        "        z = z * embedding\n",
        "\n",
        "        return self.deconvolutions(z)\n",
        "\n",
        "# Output from the network: (batch_size, channels, width, height)\n",
        "# torch.squeeze() to get rid of the channels dimension (which is 1 in this case)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMGy5h8M1-c9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConditionalDiscriminator(nn.Module):\n",
        "    r\"\"\"Discriminator of the CGAN setup\n",
        "    \"\"\"\n",
        "    def __init__(self, img_dim, num_classes):\n",
        "        super(ConditionalDiscriminator, self).__init__()\n",
        "\n",
        "        self.img_dim = img_dim\n",
        "\n",
        "        # Convert the label into an embedding\n",
        "        self.embedding_layer = nn.Embedding(num_classes, img_dim[0] * img_dim[1])\n",
        "\n",
        "        self.convolutions = nn.Sequential(\n",
        "            nn.Conv2d(2, 64, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # Output: 14x14\n",
        "\n",
        "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # Output: 7x7\n",
        "\n",
        "            nn.Conv2d(128, 128, 5, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # Output: 3x3\n",
        "\n",
        "            nn.Conv2d(128, 1, 3, 1, 0, bias=False)\n",
        "        )\n",
        "\n",
        "    def forward(self, inp, label):\n",
        "        # Create embedding of label\n",
        "        embedding = self.embedding_layer(label)\n",
        "        # Reshape embedding to size of input image\n",
        "        embedding = torch.unsqueeze(torch.reshape(embedding, (-1, self.img_dim[1], self.img_dim[0])), 1)\n",
        "        # Stack embedding on top of image\n",
        "        inp = torch.cat((inp, embedding), axis=1)\n",
        "\n",
        "        return self.convolutions(inp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0hr2h2ooitX",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gKNUOFewO6u",
        "colab_type": "text"
      },
      "source": [
        "I use the Lookahead wrapper on Adam, I've found it to stabilize training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEOXy-njnR9B",
        "colab_type": "text"
      },
      "source": [
        "Lookahead optimizer implementation from [Michael Zhang's Github repo](https://github.com/michaelrzhang/lookahead/blob/master/lookahead_pytorch.py)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ikR1TY2cDj9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Lookahead(Optimizer):\n",
        "    r\"\"\"PyTorch implementation of the lookahead wrapper.\n",
        "    Lookahead Optimizer: https://arxiv.org/abs/1907.08610\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, optimizer, la_steps=5, la_alpha=0.8, pullback_momentum=\"none\"):\n",
        "        \"\"\"optimizer: inner optimizer\n",
        "        la_steps (int): number of lookahead steps\n",
        "        la_alpha (float): linear interpolation factor. 1.0 recovers the inner optimizer.\n",
        "        pullback_momentum (str): change to inner optimizer momentum on interpolation update\n",
        "        \"\"\"\n",
        "        self.optimizer = optimizer\n",
        "        self._la_step = 0  # counter for inner optimizer\n",
        "        self.la_alpha = la_alpha\n",
        "        self._total_la_steps = la_steps\n",
        "        pullback_momentum = pullback_momentum.lower()\n",
        "        assert pullback_momentum in [\"reset\", \"pullback\", \"none\"]\n",
        "        self.pullback_momentum = pullback_momentum\n",
        "\n",
        "        self.state = defaultdict(dict)\n",
        "\n",
        "        # Cache the current optimizer parameters\n",
        "        for group in optimizer.param_groups:\n",
        "            for p in group['params']:\n",
        "                param_state = self.state[p]\n",
        "                param_state['cached_params'] = torch.zeros_like(p.data)\n",
        "                param_state['cached_params'].copy_(p.data)\n",
        "                if self.pullback_momentum == \"pullback\":\n",
        "                    param_state['cached_mom'] = torch.zeros_like(p.data)\n",
        "\n",
        "    def __getstate__(self):\n",
        "        return {\n",
        "            'state': self.state,\n",
        "            'optimizer': self.optimizer,\n",
        "            'la_alpha': self.la_alpha,\n",
        "            '_la_step': self._la_step,\n",
        "            '_total_la_steps': self._total_la_steps,\n",
        "            'pullback_momentum': self.pullback_momentum\n",
        "        }\n",
        "\n",
        "    def zero_grad(self):\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "    def get_la_step(self):\n",
        "        return self._la_step\n",
        "\n",
        "    def state_dict(self):\n",
        "        return self.optimizer.state_dict()\n",
        "\n",
        "    def load_state_dict(self, state_dict):\n",
        "        self.optimizer.load_state_dict(state_dict)\n",
        "\n",
        "    def _backup_and_load_cache(self):\n",
        "        \"\"\"Useful for performing evaluation on the slow weights (which typically generalize better)\n",
        "        \"\"\"\n",
        "        for group in self.optimizer.param_groups:\n",
        "            for p in group['params']:\n",
        "                param_state = self.state[p]\n",
        "                param_state['backup_params'] = torch.zeros_like(p.data)\n",
        "                param_state['backup_params'].copy_(p.data)\n",
        "                p.data.copy_(param_state['cached_params'])\n",
        "\n",
        "    def _clear_and_load_backup(self):\n",
        "        for group in self.optimizer.param_groups:\n",
        "            for p in group['params']:\n",
        "                param_state = self.state[p]\n",
        "                p.data.copy_(param_state['backup_params'])\n",
        "                del param_state['backup_params']\n",
        "\n",
        "    @property\n",
        "    def param_groups(self):\n",
        "        return self.optimizer.param_groups\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        \"\"\"Performs a single Lookahead optimization step.\n",
        "        Arguments:\n",
        "            closure (callable, optional): A closure that reevaluates the model\n",
        "                and returns the loss.\n",
        "        \"\"\"\n",
        "        loss = self.optimizer.step(closure)\n",
        "        self._la_step += 1\n",
        "\n",
        "        if self._la_step >= self._total_la_steps:\n",
        "            self._la_step = 0\n",
        "            # Lookahead and cache the current optimizer parameters\n",
        "            for group in self.optimizer.param_groups:\n",
        "                for p in group['params']:\n",
        "                    param_state = self.state[p]\n",
        "                    p.data.mul_(self.la_alpha).add_(1.0 - self.la_alpha, param_state['cached_params'])  # crucial line\n",
        "                    param_state['cached_params'].copy_(p.data)\n",
        "                    if self.pullback_momentum == \"pullback\":\n",
        "                        internal_momentum = self.optimizer.state[p][\"momentum_buffer\"]\n",
        "                        self.optimizer.state[p][\"momentum_buffer\"] = internal_momentum.mul_(self.la_alpha).add_(\n",
        "                            1.0 - self.la_alpha, param_state[\"cached_mom\"])\n",
        "                        param_state[\"cached_mom\"] = self.optimizer.state[p][\"momentum_buffer\"]\n",
        "                    elif self.pullback_momentum == \"reset\":\n",
        "                        self.optimizer.state[p][\"momentum_buffer\"] = torch.zeros_like(p.data)\n",
        "\n",
        "        return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DigBVCup8LW-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_CLASSES = 10\n",
        "IMG_DIM = (28, 28)\n",
        "\n",
        "# Initialize networks\n",
        "gen = ConditionalGenerator(Z_LEN, NUM_CLASSES).to(device)\n",
        "gen.apply(weights_initialization)\n",
        "\n",
        "dis = ConditionalDiscriminator(IMG_DIM, NUM_CLASSES).to(device)\n",
        "# I found it to work better without weight initialization\n",
        "# dis.apply(weights_initialization)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPasByKF8Ynz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "e66e926c-c3e7-4a19-d5ab-1cc2d2c3edc6"
      },
      "source": [
        "print(gen)\n",
        "print(dis)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ConditionalGenerator(\n",
            "  (embedding_layer): Embedding(10, 100)\n",
            "  (deconvolutions): Sequential(\n",
            "    (0): ConvTranspose2d(100, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
            "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): ConvTranspose2d(64, 1, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
            "    (10): Tanh()\n",
            "  )\n",
            ")\n",
            "ConditionalDiscriminator(\n",
            "  (embedding_layer): Embedding(10, 784)\n",
            "  (convolutions): Sequential(\n",
            "    (0): Conv2d(2, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (5): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (8): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6fdiiCUtNHJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "5f29974c-c77f-4580-bd52-35778c415009"
      },
      "source": [
        "# Passing data through the network to check input and output shapes\n",
        "for xbatch in trainloader:\n",
        "    inps, lbls = xbatch\n",
        "    inps = inps.to(device)\n",
        "    lbls = lbls.to(device)\n",
        "    xgen_inps = generate_noise(BATCH_SIZE)\n",
        "    gout = gen(xgen_inps, lbls)\n",
        "    dout = dis(inps, lbls)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([128, 100, 1, 1])\n",
            "Label shape: torch.Size([128])\n",
            "Embedding shape: torch.Size([128, 100, 1, 1])\n",
            "After multiplication: torch.Size([128, 100, 1, 1])\n",
            "Input shape: torch.Size([128, 1, 28, 28])\n",
            "Label shape: torch.Size([128])\n",
            "Raw embedding shape: torch.Size([128, 784])\n",
            "Embedding shape: torch.Size([128, 1, 28, 28])\n",
            "Shape after stacking: torch.Size([128, 2, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qa_zUzcM8ejz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define loss criterion\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Define optimizers\n",
        "gen_opt = optim.Adam(gen.parameters(), lr=0.001, betas=(BETA1, BETA2))\n",
        "gen_opt = Lookahead(optimizer=gen_opt, la_steps=10)\n",
        "\n",
        "dis_opt = optim.Adam(dis.parameters(), lr=0.001, betas=(BETA1, BETA2))\n",
        "dis_opt = Lookahead(optimizer=dis_opt, la_steps=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5NHJaH584Ti",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8304349f-473a-4a64-d2ca-150443a2caa2"
      },
      "source": [
        "EPOCHS = 100\n",
        "\n",
        "# Training loop\n",
        "# Yes, I dumped the entire training code inside the loop instead of making \n",
        "# a different function. Sue me.\n",
        "for epoch in range(EPOCHS):\n",
        "    gen_loss_list = []\n",
        "    dis_loss_list = []\n",
        "    for batch in trainloader:\n",
        "        imgs, labels = batch\n",
        "        imgs = imgs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Reset discriminator gradients\n",
        "        dis_opt.zero_grad()\n",
        "\n",
        "        # Train discriminator on real inputs\n",
        "        real_outputs = dis(imgs, labels)\n",
        "        real_labels = torch.ones_like(real_outputs)\n",
        "        real_loss = criterion(real_outputs, real_labels)\n",
        "        real_loss.backward()\n",
        "\n",
        "        # Train discriminator on fake inputs\n",
        "        gen_inputs = generate_noise(labels.shape[0])\n",
        "        fake_inputs = gen(gen_inputs, labels)\n",
        "        fake_outputs = dis(fake_inputs, labels)\n",
        "        fake_labels = torch.zeros_like(fake_outputs)\n",
        "        fake_loss = criterion(fake_outputs, fake_labels)\n",
        "        fake_loss.backward()\n",
        "\n",
        "        total_dis_loss = real_loss + fake_loss\n",
        "        dis_loss_list.append(total_dis_loss.detach().cpu().numpy())\n",
        "\n",
        "        # Update discriminator parameters\n",
        "        dis_opt.step()\n",
        "\n",
        "        # Reset generator gradients\n",
        "        gen_opt.zero_grad()\n",
        "\n",
        "        # Train generator\n",
        "        gen_inputs = generate_noise(BATCH_SIZE)\n",
        "        gen_labels = torch.randint(0, 10, (BATCH_SIZE,)).to(device)\n",
        "        dis_inputs = gen(gen_inputs, gen_labels)\n",
        "        dis_outputs = dis(dis_inputs, gen_labels)\n",
        "        dis_labels = torch.ones_like(dis_outputs)\n",
        "        gen_loss = criterion(dis_outputs, dis_labels)\n",
        "        gen_loss_list.append(gen_loss.detach().cpu().numpy())\n",
        "        gen_loss.backward()\n",
        "\n",
        "        # Update generator parameters\n",
        "        gen_opt.step()\n",
        "    \n",
        "    # Print epoch details\n",
        "    print(f'Epoch: {epoch}, Generator loss: {np.mean(gen_loss_list)}, Discriminator loss: {np.mean(dis_loss_list)}')\n",
        "\n",
        "print('Finished training')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:89: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Generator loss: 2.2236168384552, Discriminator loss: 0.9617975950241089\n",
            "Epoch: 1, Generator loss: 0.8709059357643127, Discriminator loss: 1.3322042226791382\n",
            "Epoch: 2, Generator loss: 0.7766062021255493, Discriminator loss: 1.3698444366455078\n",
            "Epoch: 3, Generator loss: 0.7466338276863098, Discriminator loss: 1.3795934915542603\n",
            "Epoch: 4, Generator loss: 0.7342373728752136, Discriminator loss: 1.3832719326019287\n",
            "Epoch: 5, Generator loss: 0.7296650409698486, Discriminator loss: 1.3854501247406006\n",
            "Epoch: 6, Generator loss: 0.722680926322937, Discriminator loss: 1.3851937055587769\n",
            "Epoch: 7, Generator loss: 0.723686695098877, Discriminator loss: 1.385919213294983\n",
            "Epoch: 8, Generator loss: 0.7244465947151184, Discriminator loss: 1.3853338956832886\n",
            "Epoch: 9, Generator loss: 0.7237581610679626, Discriminator loss: 1.3860617876052856\n",
            "Epoch: 10, Generator loss: 0.7217431664466858, Discriminator loss: 1.3853716850280762\n",
            "Epoch: 11, Generator loss: 0.7221860289573669, Discriminator loss: 1.3855352401733398\n",
            "Epoch: 12, Generator loss: 0.721206784248352, Discriminator loss: 1.3845771551132202\n",
            "Epoch: 13, Generator loss: 0.7220279574394226, Discriminator loss: 1.384019136428833\n",
            "Epoch: 14, Generator loss: 0.7244831323623657, Discriminator loss: 1.3830510377883911\n",
            "Epoch: 15, Generator loss: 0.7271097302436829, Discriminator loss: 1.380692720413208\n",
            "Epoch: 16, Generator loss: 0.7282503843307495, Discriminator loss: 1.3791903257369995\n",
            "Epoch: 17, Generator loss: 0.729444682598114, Discriminator loss: 1.3779473304748535\n",
            "Epoch: 18, Generator loss: 0.7305578589439392, Discriminator loss: 1.3761416673660278\n",
            "Epoch: 19, Generator loss: 0.7309885025024414, Discriminator loss: 1.3760254383087158\n",
            "Epoch: 20, Generator loss: 0.7316925525665283, Discriminator loss: 1.37380850315094\n",
            "Epoch: 21, Generator loss: 0.7312583923339844, Discriminator loss: 1.3725817203521729\n",
            "Epoch: 22, Generator loss: 0.7349382042884827, Discriminator loss: 1.3705615997314453\n",
            "Epoch: 23, Generator loss: 0.7391776442527771, Discriminator loss: 1.3666315078735352\n",
            "Epoch: 24, Generator loss: 0.7433216571807861, Discriminator loss: 1.3652936220169067\n",
            "Epoch: 25, Generator loss: 0.7406893372535706, Discriminator loss: 1.3624272346496582\n",
            "Epoch: 26, Generator loss: 0.7472405433654785, Discriminator loss: 1.3612401485443115\n",
            "Epoch: 27, Generator loss: 0.7541386485099792, Discriminator loss: 1.3562649488449097\n",
            "Epoch: 28, Generator loss: 0.7579726576805115, Discriminator loss: 1.3507850170135498\n",
            "Epoch: 29, Generator loss: 0.76438307762146, Discriminator loss: 1.3474199771881104\n",
            "Epoch: 30, Generator loss: 0.7687627673149109, Discriminator loss: 1.342445731163025\n",
            "Epoch: 31, Generator loss: 0.7715467810630798, Discriminator loss: 1.3372883796691895\n",
            "Epoch: 32, Generator loss: 0.7828599214553833, Discriminator loss: 1.3308804035186768\n",
            "Epoch: 33, Generator loss: 0.7890105247497559, Discriminator loss: 1.3273063898086548\n",
            "Epoch: 34, Generator loss: 0.7974995374679565, Discriminator loss: 1.3199715614318848\n",
            "Epoch: 35, Generator loss: 0.8051933646202087, Discriminator loss: 1.3150707483291626\n",
            "Epoch: 36, Generator loss: 0.813229501247406, Discriminator loss: 1.3084685802459717\n",
            "Epoch: 37, Generator loss: 0.8247965574264526, Discriminator loss: 1.2955878973007202\n",
            "Epoch: 38, Generator loss: 0.8371644616127014, Discriminator loss: 1.2949100732803345\n",
            "Epoch: 39, Generator loss: 0.8506627082824707, Discriminator loss: 1.2810074090957642\n",
            "Epoch: 40, Generator loss: 0.8561969995498657, Discriminator loss: 1.2746020555496216\n",
            "Epoch: 41, Generator loss: 0.8723170161247253, Discriminator loss: 1.268632173538208\n",
            "Epoch: 42, Generator loss: 0.8784342408180237, Discriminator loss: 1.2663530111312866\n",
            "Epoch: 43, Generator loss: 0.8934179544448853, Discriminator loss: 1.2566243410110474\n",
            "Epoch: 44, Generator loss: 0.9075940251350403, Discriminator loss: 1.2436832189559937\n",
            "Epoch: 45, Generator loss: 0.9198184013366699, Discriminator loss: 1.2310470342636108\n",
            "Epoch: 46, Generator loss: 0.9333376288414001, Discriminator loss: 1.2245538234710693\n",
            "Epoch: 47, Generator loss: 0.9479649066925049, Discriminator loss: 1.217716097831726\n",
            "Epoch: 48, Generator loss: 0.9543771743774414, Discriminator loss: 1.210760235786438\n",
            "Epoch: 49, Generator loss: 0.9718445539474487, Discriminator loss: 1.1995937824249268\n",
            "Epoch: 50, Generator loss: 0.9900429248809814, Discriminator loss: 1.1954727172851562\n",
            "Epoch: 51, Generator loss: 1.0061261653900146, Discriminator loss: 1.181136965751648\n",
            "Epoch: 52, Generator loss: 1.0102750062942505, Discriminator loss: 1.1751070022583008\n",
            "Epoch: 53, Generator loss: 1.0379658937454224, Discriminator loss: 1.1633111238479614\n",
            "Epoch: 54, Generator loss: 1.0465397834777832, Discriminator loss: 1.1561644077301025\n",
            "Epoch: 55, Generator loss: 1.0753612518310547, Discriminator loss: 1.1492626667022705\n",
            "Epoch: 56, Generator loss: 1.0811100006103516, Discriminator loss: 1.1364384889602661\n",
            "Epoch: 57, Generator loss: 1.1008983850479126, Discriminator loss: 1.1272467374801636\n",
            "Epoch: 58, Generator loss: 1.1098065376281738, Discriminator loss: 1.1209052801132202\n",
            "Epoch: 59, Generator loss: 1.1268666982650757, Discriminator loss: 1.1089801788330078\n",
            "Epoch: 60, Generator loss: 1.1482596397399902, Discriminator loss: 1.100903034210205\n",
            "Epoch: 61, Generator loss: 1.1714643239974976, Discriminator loss: 1.0952271223068237\n",
            "Epoch: 62, Generator loss: 1.1899664402008057, Discriminator loss: 1.0805015563964844\n",
            "Epoch: 63, Generator loss: 1.1959272623062134, Discriminator loss: 1.0729780197143555\n",
            "Epoch: 64, Generator loss: 1.2314345836639404, Discriminator loss: 1.0635319948196411\n",
            "Epoch: 65, Generator loss: 1.2342581748962402, Discriminator loss: 1.0594202280044556\n",
            "Epoch: 66, Generator loss: 1.2487355470657349, Discriminator loss: 1.0492572784423828\n",
            "Epoch: 67, Generator loss: 1.2659814357757568, Discriminator loss: 1.0410579442977905\n",
            "Epoch: 68, Generator loss: 1.2843480110168457, Discriminator loss: 1.0431324243545532\n",
            "Epoch: 69, Generator loss: 1.3068733215332031, Discriminator loss: 1.0271247625350952\n",
            "Epoch: 70, Generator loss: 1.325146198272705, Discriminator loss: 1.0210736989974976\n",
            "Epoch: 71, Generator loss: 1.3438087701797485, Discriminator loss: 1.0027074813842773\n",
            "Epoch: 72, Generator loss: 1.3488329648971558, Discriminator loss: 1.0009409189224243\n",
            "Epoch: 73, Generator loss: 1.375231385231018, Discriminator loss: 0.993260383605957\n",
            "Epoch: 74, Generator loss: 1.3835262060165405, Discriminator loss: 0.9851800799369812\n",
            "Epoch: 75, Generator loss: 1.4121004343032837, Discriminator loss: 0.9710605144500732\n",
            "Epoch: 76, Generator loss: 1.438252568244934, Discriminator loss: 0.9570561051368713\n",
            "Epoch: 77, Generator loss: 1.4586999416351318, Discriminator loss: 0.9638445973396301\n",
            "Epoch: 78, Generator loss: 1.4820512533187866, Discriminator loss: 0.9463591575622559\n",
            "Epoch: 79, Generator loss: 1.4850589036941528, Discriminator loss: 0.9463115334510803\n",
            "Epoch: 80, Generator loss: 1.5071501731872559, Discriminator loss: 0.9328824877738953\n",
            "Epoch: 81, Generator loss: 1.5215842723846436, Discriminator loss: 0.9278572201728821\n",
            "Epoch: 82, Generator loss: 1.5399441719055176, Discriminator loss: 0.9212480187416077\n",
            "Epoch: 83, Generator loss: 1.565649151802063, Discriminator loss: 0.9155668020248413\n",
            "Epoch: 84, Generator loss: 1.5712567567825317, Discriminator loss: 0.9197363257408142\n",
            "Epoch: 85, Generator loss: 1.5817441940307617, Discriminator loss: 0.9028886556625366\n",
            "Epoch: 86, Generator loss: 1.592098593711853, Discriminator loss: 0.8983832597732544\n",
            "Epoch: 87, Generator loss: 1.6241157054901123, Discriminator loss: 0.9135666489601135\n",
            "Epoch: 88, Generator loss: 1.6393725872039795, Discriminator loss: 0.8784295320510864\n",
            "Epoch: 89, Generator loss: 1.6682666540145874, Discriminator loss: 0.8772944211959839\n",
            "Epoch: 90, Generator loss: 1.6742393970489502, Discriminator loss: 0.8821856379508972\n",
            "Epoch: 91, Generator loss: 1.710111141204834, Discriminator loss: 0.8736069798469543\n",
            "Epoch: 92, Generator loss: 1.7116574048995972, Discriminator loss: 0.8580111265182495\n",
            "Epoch: 93, Generator loss: 1.7147023677825928, Discriminator loss: 0.8628154993057251\n",
            "Epoch: 94, Generator loss: 1.737260341644287, Discriminator loss: 0.8512123227119446\n",
            "Epoch: 95, Generator loss: 1.7688146829605103, Discriminator loss: 0.8409786820411682\n",
            "Epoch: 96, Generator loss: 1.7940990924835205, Discriminator loss: 0.8428577780723572\n",
            "Epoch: 97, Generator loss: 1.8209158182144165, Discriminator loss: 0.8297021389007568\n",
            "Epoch: 98, Generator loss: 1.8093976974487305, Discriminator loss: 0.8265129327774048\n",
            "Epoch: 99, Generator loss: 1.842594861984253, Discriminator loss: 0.8131211400032043\n",
            "Finished training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IbIu6U8oMZf",
        "colab_type": "text"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEXuOpDcoIVF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_number(number):\n",
        "    with torch.no_grad():\n",
        "        pred_in = generate_noise(1)\n",
        "        pred_lbl = torch.tensor([number], dtype=torch.long, device=device)\n",
        "        generated = torch.squeeze(gen(pred_in, pred_lbl).detach().cpu())\n",
        "        display_img(generated, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXSotZky0WT-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "1d5d9042-ad5f-4702-819e-f73603681625"
      },
      "source": [
        "generate_number(4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6BBmxJu0Ypl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "7367bb50-f1f6-4489-d3d0-cb0ea2d69ee9"
      },
      "source": [
        "generate_number(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_i4dBAInfMi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "ace5bd43-ac9b-4651-be49-b8fe94d93e1b"
      },
      "source": [
        "generate_number(8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efSnK77Mqurh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(gen.state_dict(), './cgan_gen_state_dict.pt')\n",
        "torch.save(dis.state_dict(), './cgan_dis_state_dict.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxzSm_mFz8wF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading saved model\n",
        "Z_LEN = 100\n",
        "NUM_CLASSES = 10\n",
        "\n",
        "generator = ConditionalGenerator(Z_LEN, NUM_CLASSES)\n",
        "generator.load_state_dict(torch.load('./cgan_gen_state_dict.pt', map_location=device))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}